{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a998d01b",
   "metadata": {},
   "source": [
    "# <font color='blue'> <center> Classic Control: Control theory problems from the classic RL literature </center> </font>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "In this notebook we will present some classic environments in Reinforcement Learning research. These environments have continuous states spaces (i.e., infinite possible states) and therefore tabular methods cannot solve them. To tackle these environments (and more complex ones) we will have two tools:\n",
    "\n",
    "- Extend the tabular methods with the techniques of discretization and tile coding\n",
    "- Use function approximators (Neural Networks)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057724a5",
   "metadata": {},
   "source": [
    "## <font color='#2874A6'> Tabla de Contenido </font>\n",
    "\n",
    "1. [Modules](#1)\n",
    "2. [Setup Code](#2)\n",
    "3. [Algorithm](#3)\n",
    "4. [Results](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1664235c",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## <font color='#0E6655'> 1. Modules </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a4b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
